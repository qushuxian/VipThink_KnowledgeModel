# 贝叶斯知识点追踪模型

## BKT模型业务应用待解决问题

| 待解决问题                                                   | 解决方案                                                     | 状态                                                         |
| ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| BKT模型最终是根据贝叶斯公式在不同$obs_t$下的后验概率值，并未对知识点掌握与否给出直接的结果，而实际业务最终需要的是学生在某个末级知识点是否掌握。 | 根据知识点下不同题目的作答成绩、求解后验概率有没有满足seed(默认≥0.85)的条件，然后返回用户ID，末级知识点ID，末级知识点掌握状态分类（0 \| 1），掌握值 | <span style="white-space:nowrap;">[已解决](#ng_state)&emsp;&emsp;</span> |
| BKT模型是根据历史答题数据拟合出学习参数和表现参数，但如果末级知识点在拟合时所有的学生都为学过、则不会得出相关参数、也就意味着模型对未来新学习数据鲁棒性极差。 | 在对知识点预测时，若知识点在模型拟合得到的参数中不存在：<br>1、返回不预测的结果<br/>2、对新知识点进行拟合，并进行预测，但这种状况下因为新知识点观测值较少、结果不一定理想。 | 待解决                                                       |
| 现实业务中V3版本42讲之后的实际答题数据有5000W+的数据量，模型在首次拟合时将极大地耗费算力和时间。 | 1、目前已拟合21年3月的答题数据，AUC0.61，还需要把剩余的数据进行拟合。<br> | 待解决                                                       |

<br>

<br>

## BKT模型简介

>   贝叶斯知识点追踪模型（BKT）是知识追踪最常用的一个模型，是含有隐变量的马尔可夫模型（HMM），BKT通过对学生的每个知识点单独建模来了解学生特定知识点的掌握情况（模型无法表示知识点间的相关性）。
>
>   它假设每个知识点由猜测率、学习率、失误率和学习知识之前的先验概率4个参数组成，目前已经发展成为智能辅导系统中对学习者知识掌握情况建模的主流方法。

![image-20210521220112874](../static_files/image-20210521220112874.png)

如左上图，BKT是一个马尔可夫过程，自身含有知识点掌握和不掌握的隐藏状态。通过当下答题的表现状态，重新计算P(T)值并传递给下一个知识点。其中可见节点表示学生对于已知的二值问题答题结果序列obst，而隐藏节点表示学生的潜在知识状态。BKT从历史学生答题数据中拟合得到学习参数（learn）、猜测参数（guess）和失误参数（slip），参数定义如下：
$$
prior = P(L_{0})
$$

$$
learn = P(T) = P(L_{t+1} = 1|L_t=0)
$$

$$
guess = P(G) = P(obs_t = 1|L_t=0)
$$

$$
slip = P(S) = P(obs_t = 0|L_t=1)
$$

需要注意的是，$P(L_{0})$虽然表示先验概率，但BKT模型还将$P(L_t)$定义为学生在不同时间下的掌握概率。之后会根据新的答题数据掌握与否重新并更新$P(L_t)$，也可以称之为更新$P(L_t)$的后验概率，计算如下：
$$
P(L_t|obs_t = 1) = \frac{P(L_t)(1-P(S))}{P(L_t)(1-P(S))  +  (1-P(L_t))P(G)}
$$

$$
P(L_t|obs_t = 0) = \frac{P(L_t)P(S)}{P(L_t)P(S)  +  (1-P(L_t))(1-P(G))}
$$

更新后的先验不包括从即时反馈和任何其他教学支持中吸取学习的可能性，定义如下：
$$
P(L_{t+1}) = P(L_t|obs_t) + (1-P(L_t|obs_t))P(T)
$$


在标准的BKT模型中是假设学习过后不存在遗忘的情况，定义如下：
$$
P(F) = P(L_{t+1}=0|L_t=1)=0
$$




每一个节点都通过条件概率表（下图）来量化父节点对自身的影响。

![image-20210521222840848](../static_files/image-20210521222840848.png)

<br>

BKT同时支持对不同的的知识点单独进行建模的，理论上来说，训练数据有多少个知识点，就有多少组对应的（L0,T,G,S）参数。

| 学习参数     | 初始概率P(L0) = Intirial Knowledge，表示学生的未开始做这道题目时或开始连续这项知识点的时候，掌握概率 |
| ------------ | ------------------------------------------------------------ |
| **学习参数** | **学习概率P(T) = Probability of learning，表示学生经过做题练习后，知识点从不会到学会的概率** |
| **表现参数** | **猜测概率P(G) = Probability of guess，表示学生没掌握这项知识点，但是还是蒙对的概率** |
| **表现参数** | **失误概率P(S) = Probability of slip，表示学生实际上掌握了这项知识点，但是还是给做错了的概率** |
| **遗忘参数** | **遗忘概率P(F) = Probability of forgets，表示学生对这项知识点，从会做到遗忘的概率** |

如上，每次学生答题后模型都会根据答题正误的序列利用贝叶斯公式迭代更新其对知识的掌握情况。当P（G）和P（S）都为0时，说明学习者答题不存在猜测和失误情况，答题结果将会客观真实地反映学习者的知识水平；如果P（G）和P（S）值大于0.5，说明知识追踪模型出现模型退化现象，学习者回答问题的结果不能用来反映其真实知识水平。

<br>

<br>

## BKT模型应用

示例数据（下表仅展现部分）

Row：答题时间序列号

Anon Student Id：学生ID

Problem Name：知识点下题目

正确的第一次尝试：题目下第一次答题结果，0错误，1正确

KC(Default)：知识点

| Row     | Anon Student Id | Problem Name | Correct First Attempt | KC(Default)         |
| ------- | --------------- | ------------ | --------------------- | ------------------- |
| 113913  | 0I891Gg         | RATIO2-001   | 1                     | Calculate unit rate |
| 113923  | 0I891Gg         | RATIO2-001   | 0                     | Calculate unit rate |
| 113932  | 0I891Gg         | RATIO2-074   | 0                     | Calculate unit rate |
| 113940  | 0I891Gg         | RATIO2-074   | 1                     | Calculate unit rate |
| 113949  | 0I891Gg         | RATIO2-069   | 1                     | Calculate unit rate |
| 113957  | 0I891Gg         | RATIO2-069   | 1                     | Calculate unit rate |
| 1660187 | 171017OL        | RATIO2-001   | 1                     | Calculate unit rate |
| 1660197 | 171017OL        | RATIO2-001   | 0                     | Calculate unit rate |
| 1660205 | 171017OL        | RATIO2-188   | 1                     | Calculate unit rate |
| 1660212 | 171017OL        | RATIO2-188   | 1                     | Calculate unit rate |
| 1660221 | 171017OL        | RATIO2-035   | 1                     | Calculate unit rate |
| 1660229 | 171017OL        | RATIO2-035   | 1                     | Calculate unit rate |

### Step1 构建模型

```python
model = Model(num_fits=2)
model.coef_ = {'Calculate unit rate': {'prior': 0.5}}
```

num_fits：采用交叉验证的次数，此处采用2次

prior：初始概率$P(L_0)$

<br>

### Step2 拟合模型

```python
model.fit(data=ct_df)
```

#### **拟合过程概况分析**

##### 1、根据skill(不同的知识点)循环计算

###### 1.1 model定义的num_fits循环请求初始化参数

根据拟合模型传入的:

num_learns(数据集中的resource_names)，默认为1

num_gs(数据集中的gs_names)，默认为1

trans_prior（根据数据集中的resource_names数据量将默认值array([[[20,1], [4,20]]])进行横纵向扩展）
given_notknow_prior，默认为array([[5.0], [0.5]])

given_know_prior，默认为array([[0.5], [5.0]])

pi_0_prior，默认为array([[100], [1]])

之后将trans_prior、given_notknow_prior、given_know_prior、pi_0_prior进行gamma计算，given_notknow_priorgamma计算后纵向添加num_gs维。

>   **Gamma分布即为多个独立且相同分布（iid）的指数分布变量的和的分布。**
>
>   伽玛分布 = 指数分布＊泊松分布
>
>   反映到模型当中就是当拟合函数传入的数据集根据泊松分布计算过程求解满足gamma值所需要的做题数量。

```python
# num_fits=0
# 根据拟合传入的参数，gama计算后得到的初始化学习参数和表现参数
{'prior': 0.4457060630095818, 
 'learns': array([0.08152828]), 
 'forgets': array([0.]), 
 'guesses': array([0.25530859]), 
 'slips': array([0.04539381]), 
 'As': array([[[1.        , 0.        ],[0.08152828, 0.91847172]]]), 
 'emissions': array([[[0.97444928, 0.02555072],[0.01894198, 0.98105802]]]), 
 'pi_0': array([[9.99578341e-01],[4.21659067e-04]])
}
# 拟合前若定义初始概率则修正初始化概率
{'prior': 0.5, 
 'learns': array([0.08152828]), 
 'forgets': array([0.]), 
 'guesses': array([0.25530859]), 
 'slips': array([0.04539381]), 
 'As': array([[[1.        , 0.        ],[0.08152828, 0.91847172]]]), 
 'emissions': array([[[0.97444928, 0.02555072],[0.01894198, 0.98105802]]]), 
 'pi_0': array([[9.99578341e-01],[4.21659067e-04]])
}
```

###### 1.2 得到初始化初始化参数后根据EM算法对隐马尔科夫模型进行计算并更新概率值

>   EM算法：
>
>   最大似然估计根本目的是根据抽样的到的样本，反推出最有可能的分布参数（即模型）。然而，如果已知的数据中含有某些无法观测的隐藏变量时（例如知识点掌握与否对应的是题目作答，而题目作答又是多分类数据），直接使用最大似然估计是不足以解决问题的，这个时候就要依靠[EM(期望最大化)算法](https://blog.csdn.net/guoziqing506/article/details/81274276)。简单的说，EM算法是在依赖于无法观测的隐藏变量的概率模型中，寻找参数最大似然估计或者最大后验估计的算法。
>
>   1. 最大似然估计
>
>       假设我们手里现在有一个样本，这个样本服从某种分布，而分布有参数，可如果我现在不知道这个样本分布的具体参数是多少，我们就想要通过抽样得到的样本进行分析，从而估计出一个较准确的相关参数。以上，这种通过抽样结果反推分布参数的方法就是“最大似然估计”。
>
>   2. 隐藏变量
>
>       最大似然估计仅适用于不存在隐藏变量的概率模型。什么是隐藏变量？属于多个类别的样本混在一起，不同类别样本的参数不同，现在的任务是从总体中抽样，再通过抽样数据估计每个类别的分布参数。这个描述就是所谓的“在依赖于无法观测的隐藏变量的概率模型中，寻找参数最大似然估计”，隐藏变量在此处就是样本的类别，这个时候EM算法就派上用场了。
>
>   3. EM算法思想
>
>       直观考虑这种隐藏变量的问题，会使得人们陷入了一种两难的境地：我只有知道了哪些样本是属于同一个类别的，才能根据最大似然函数估计这个类别样本的分布参数；同样，我只有知道了不同类别样本的分布参数，才有可能判断现某个样本到底属于哪个类别的可能性更大。
>
>       也就是说，你不确定，我就确定不了；而我不确定，你也确定不了。此时我们可以先让其中一方随便确定一个值，然后用根据这个值看看对方如何变化，再根据对方的变化调整己方，这样你根据我调整，我再根据你调整，循环往复，最终双方都达到了收敛，也就是调整值几乎不变，那就可以确定相关的值了。
>
>       EM的求解思路
>
>       （1）我们先根据经验为每个类别（即隐藏变量）赋予一个初始分布，这相当于是假定了分布参数。然后根据分布的参数可以求取每个数据元组的隐藏变量的期望（相当于实施了归类操作）；
>
>       （2）再根据归类结果计算分布参数（向量）的最大似然值，然后根据这个最大似然值在反过来重新计算每个元组的隐藏变量的期望。
>
>       这样循环反复迭代，直到收敛（最终如果隐藏变量的期望与参数的最大似然值趋于稳定了），EM算法就算是执行完毕了。
>
>       
>
>   综上，EM算法由两步组成，第一步是E步，就是求期望；第二步是M步，就是最大化：
>
>   E步(Expectation)：根据当前的参数值，计算样本隐藏变量的期望；
>   M步(Maximum)：根据当前样本的隐藏变量，求解参数的最大似然估计；
>
>   [1] https://zhuanlan.zhihu.com/p/28298205
>
>   [2] https://zhuanlan.zhihu.com/p/28298944

```python
# 将修正后的初始化概率和数据代入EM算法
# 根据EM的求解思路（默认循环100次，收敛值为0.001），迭代求解最大似然估计值
# num_fits=0求解的最大似然估计参数值
{'prior': 0.5325490088332778, 
 'learns': array([0.00132258]), 
 'forgets': array([0.]), 
 'guesses': array([0.31584889]), 
 'slips': array([0.47342687]), 
 'As': array([[[0.99867742, 0.        ],[0.00132258, 1.        ]]]), 
 'emissions': array([[[0.68415111, 0.31584889],[0.47342687, 0.52657313]]]), 
 'pi_0': array([[0.46745099],[0.53254901]])}


# num_fits=1
# 根据拟合传入的参数，gama计算后得到的初始化学习参数和表现参数
{'prior': 0.717138422013306, 
 'learns': array([0.04719056]), 
 'forgets': array([0.]), 
 'guesses': array([0.04869282]), 
 'slips': array([0.23690063]), 
 'As': array([[[1.        , 0.        ],[0.04719056, 0.95280944]]]), 
 'emissions': array([[[0.98643378, 0.01356622],[0.02114708, 0.97885292]]]), 
 'pi_0': array([[0.9806825],[0.0193175]])
}
# 修正num_fits=1初始化概率
{'prior': 0.5, 
 'learns': array([0.04719056]), 
 'forgets': array([0.]), 
 'guesses': array([0.04869282]), 
 'slips': array([0.23690063]), 
 'As': array([[[1.        , 0.        ],[0.04719056, 0.95280944]]]), 
 'emissions': array([[[0.98643378, 0.01356622],[0.02114708, 0.97885292]]]), 
 'pi_0': array([[0.9806825],[0.0193175]])
}
# num_fits=1求解的最大似然估计参数值
{'prior': 0.5325701327119163, 
 'learns': array([0.00132127]), 
 'forgets': array([0.]), 
 'guesses': array([0.31587496]), 
 'slips': array([0.47339745]), 
 'As': array([[[0.99867873, 0.        ],[0.00132127, 1.        ]]]), 
 'emissions': array([[[0.68412504, 0.31587496],[0.47339745, 0.52660255]]]), 
 'pi_0': array([[0.46742987],[0.53257013]])}
```

##### 2、拟合后得到学习参数和表现参数

最后skill根据迭代（num_fits）的不同参数结果，选择prior最优的结果参数集。

```python
# 得到四个参数
{'prior': 0.5325490088332778, 
 'learns': array([0.00132258]), 
 'forgets': array([0.]), 
 'guesses': array([0.31584889]), 
 'slips': array([0.47342687]), 
 'As': array([[[0.99867742, 0.        ],[0.00132258, 1.        ]]]), 
 'emissions': array([[[0.68415111, 0.31584889],[0.47342687, 0.52657313]]]), 
 'pi_0': array([[0.46745099],[0.53254901]]), 
 'resource_names': {'default': 1}, 
 'gs_names': {'default': 1}
}
```

```python
## 拟合效果评估
print(model.evaluate(data=ct_df, metric=["auc", "rmse", "accuracy", mean_absolute_error]))
out:
    [0.568276160978505, 0.5087188905220124, 0.4733548264744927, 0.5036820125332191]

# 返回拟合后的模型参数
print(model.params())
out:
    知识点       			参数    题目名称 value
0  Calculate unit rate    prior  default 0.5325490088332778
1  Calculate unit rate   learns  default 0.00132258
2  Calculate unit rate  guesses  default 0.31584889
3  Calculate unit rate    slips  default 0.47342687
4  Calculate unit rate  forgets  default 0.00000
```

<br>

### Step3 效果评估

在业务实际应用中最终是需要知道知识点掌握与否，得到的是一个分类结果（0 | 1），但模型计算是根据知识点下$obs_t$计算不同时间下prior的后验概率，因此评估模型的表现状况只能根据原始的答题(正确=1 | 错误=0)与prior后验概率对比计算并对结果进行评估，评估指标：

```python
# 后验概率默认阈值为0.5的准确性评估
auc = .5682763103302735
rmse = .5087202856284727
accuracy = .4733548264744927
mae = 5036829422644872
```

```
auc：
	统计意义上auc≥0.8代表模型表现良好
	
rmse：
	均方根误差，表示预测值和实际观察值之间的差异的样本标准偏差，该指标说明了样本的离散程度，统计意义上值无限接近于0代表分类结果表现越好
	
accuracy：
	准确率（正确预测的样本数占总预测样本数的比值，它不考虑预测的样本是正例还是负例），作为参考评估项。
mae：
	平均绝对误差，表示预测值与观测值之间绝对误差的平均值，计意义上值无限接近于0代表分类结果表现越好
```

<br>

### Step4 数据预测

根据拟合后得到的学习和表现参数prior=0.5325490088332778，learns=0.00132258，guesses=0.31584889，slips=0.47342687，按照贝叶斯知识追踪公式推导计算答题掌握（state_predictions）情况：
$$
prior = P(L_{0})
$$

$$
learn = P(T) = P(L_{t+1} = 1|L_t=0)
$$

$$
guess = P(G) = P(obs_t = 1|L_t=0)
$$

$$
slip = P(S) = P(obs_t = 0|L_t=1)
$$

计算过程中还将$P(L_t)$定义为学生在不同$obs_t$时间下答题的掌握概率，之后会根据并更新$P(L_t)$，也可以称之为更新$P(L_t)$的后验概率，计算如下：
$$
P(L_t|obs_t = 1) = \frac{P(L_t)(1-P(S))}{P(L_t)(1-P(S))  +  (1-P(L_t))P(G)}
$$

$$
P(L_t|obs_t = 0) = \frac{P(L_t)P(S)}{P(L_t)P(S)  +  (1-P(L_t))(1-P(G))}
$$

更新后的先验不包括从即时反馈和任何其他教学支持中吸取学习的可能性，定义如下：
$$
P(L_{t+1}) = P(L_t|obs_t) + (1-P(L_t|obs_t))P(T)
$$

**选择9条数据展示预测结果如下：**

*手动计算_state是按照公式推导计算得出的，与模型预测的state_predictions完全一致。*

| Row     | Anon Student Id | Problem Name | Correct First  Attempt | KC(Default)         | state_predictions | 手动计算_state |
| ------- | --------------- | ------------ | ---------------------- | ------------------- | ----------------- | -------------- |
| 113913  | 0I891Gg         | RATIO2-001   | 1                      | Calculate unit rate | 0.53255           | 0.53255        |
| 113923  | 0I891Gg         | RATIO2-001   | 0                      | Calculate unit rate | 0.65555           | 0.65555        |
| 113932  | 0I891Gg         | RATIO2-074   | 0                      | Calculate unit rate | 0.56898           | 0.56898        |
| 113940  | 0I891Gg         | RATIO2-074   | 1                      | Calculate unit rate | 0.47808           | 0.47808        |
| 113949  | 0I891Gg         | RATIO2-069   | 1                      | Calculate unit rate | 0.60482           | 0.60482        |
| 113957  | 0I891Gg         | RATIO2-069   | 1                      | Calculate unit rate | 0.71881           | 0.71881        |
| 1660187 | 171017OL        | RATIO2-001   | 1                      | Calculate unit rate | 0.53255           | 0.81020        |
| 1660197 | 171017OL        | RATIO2-001   | 0                      | Calculate unit rate | 0.65555           | 0.87696        |
| 1660205 | 171017OL        | RATIO2-188   | 1                      | Calculate unit rate | 0.56898           | 0.83165        |

*由于模型预测的是知识点下的每道题答题数据，后续还需要根据$obs_t$中state满足业务条件再计算知识点掌握情况。*

<br>

### Step5 预测结果应用

#### <span id="ng_state">1. 求解末级知识点掌握情况</span>

```python
# 默认后验概率>=0.85为掌握知识点
def state_sift(data, group_list, seed=0.85):
    data['sift_number'] = data.apply(lambda x: x.row_number if x.state_predictions >= seed else 0, axis=1)
    group_dt = data.groupby(group_list, as_index=False).apply(lambda t: t[t.sift_number > 0].min())
    for i in group_list:
        group_dt[i] = group_dt.index.get_level_values(i)
    group_dt.reset_index(drop=True, inplace=True)
    group_list.extend(['state_predictions', 'questions_cnt', 'sift_number'])
    print(group_list)
    group_dt = group_dt[group_list]
    return group_dt


# 模型预测结果最终返回字段示例
# state_predictions为知识点的掌握概率（不同题目时间序列下首次满足seed的概率值）
# questions_cnt为知识点学生实际答题总量
# sift_number为知识点学生首次满足seed的概率值是在答第几题时发生
# nan(null)表示知识点下答题没有满足seed的概率值
{'user_id': ['111', '222', '333', '444'],
 'knowledge': ['knowledge1','knowledge2','knowledge3','knowledge4'],
 'state_predictions': [0.7035527852228158, nan, nan, 0.7478505381284793],
 'questions_cnt': [12.0, nan, nan, 10.0],
 'sift_number': [6.0, nan, nan, 8.0]
}
```



<br>











